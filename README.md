# -slam-
Object-Centric Photometric Bundle Adjustment with Deep Shape Prior

本文发表在WACV2018会议上，是CMU的一个工作，这篇文章不能算是SLAM的一个工作，属于SFM，但是其思路值得借鉴。传统的·SFM是纯几何的误差，不考虑几何形状先验，深度学习则是完全抛弃了集合误差。（对于语义SLAM而言，其实也是一样啊）.传统的SFM主要是通过特征对应（重投影误差）、光度一致性（光度误差）、轮廓约束，虽然这些都是能达到较为先进的水平，但是目前在低纹理区域、镜面反射区域等还是存在一定缺陷，本文其实就是探索一种方法。
在最小化光度误差的时候，由于逆深度和相机位姿赋予了整个系统较为强烈的几何约束，但是这种约束通常在图像梯度较强的边缘比较有效果，对于弱纹理区域仍然存在较大的缺陷，而基于深度学习的重建方法，能够较好的克服这种缺陷。
本文的主要贡献：1.点与点之间的关联是有深度学习网络输出构成2.与传统的深度学习相比，在推理是必须保证其几何一致性3.证明了形状变化相对于相机位姿和几何位置是可微的（其实这个就是一个比较关键的问题，如果通过多传感器融合的思路来实现，就必须要证明误差项相对于相机位姿和几何位置是可微的）
论文中根据深度学习生成的几何轮廓通过伪渲染的方式（就是将3D投影到2D）能够得到将几何形状转换为二维表示，形成一个可微方程。同时由于引入了这样的一个可微过程，所以他在做BA的时候，用的就不再是高斯牛顿法，因为雅克比无法求（深度学习黑箱有点麻烦），而是选择SGD、LBFGS这一类基于梯度的优化算法。
作者在论文中探讨了形状的先验在优化过程中所扮演的角色：在逆投影回去的时候，其实只有三维形状的一部分点是可见的，但是有了形状先验，就可以去更新所有点的位置（包括可见点和不可见点）。
论文中提到基于光度误差损失在所有点都不再当前帧的条件下，给出了一个0损失，这是不合理的，因此引入了倒角距离损失作为一个补充约束。
与这篇论文相关的文章如下，它是介绍伪渲染函数的，应该算是本篇论文的一个基础工作。
Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction

Long-term Visual Localization using Semantically Segmented Images

这篇论文是发表在ICRA2018上的一篇论文，主要是用来解决无人车在跨度时间较长的情况下的一个定位问题。传统的描述子对于这种光照变化会比较的敏感，所以在时间跨度较大的场景下并不能适用。本文提出了基于语义的定位方法，用语义分割去替代了特征描述子，用基于粒子滤波的方式实现了定位。
在长期定位过程中定位失败的主要原因其实是在于无法找到一个不变的特征，因为基于描述子的特征如SIFT,ORB等随着时间的变化（跨季节）会发生改变。本文设计了一种依赖于语义label和3D位置的定位算法。这个问题就变成了：给定观测的情况下如何递归的就算相对于地图，车辆的姿态的后验概率。
本文基于滤波的思路实现了定位，这里的定位特征用了SIFT和语义分割后的特征。
